---
layout: default
---

<img src="{{ site.url }}{{ site.baseurl }}/assets/img/Screenshot 2025-11-27 401.jpg">

# Executive Summary #

Algorithm bias in policing and crime prediction is significant and has already caused harmful outcomes especially for underprivileged groups like the poor and racial minorities. The primary cause for these biased outcomes is the biased data input, which the arrest data typically overrepresent racial minority groups and poor neighborhoods, regardless of actual crime convictions. However, even if input data were altered to use more neutral sources like citizen reports, due to the structural inequality, the overpolicing of certain neighborhoods with higher crime rates still persist and cause police distrust. Meanwhile, risk assessment algorithms are also being applied in judicial courts despite having problems with high inaccuracy and opaque mechanisms. My main recommendation is to use algorithms in ways other than enforcement to reduce crime at its root, while calling for greater transparency in algorithmic mechanisms, and monitor private companies and organizationsâ€™ intervention on policy decision making. 

<div style="margin: 40px 0;">
  <h2>Data Employed for This Website</h2>
  <p>Explore the data supporting our analysis of algorithmic bias in predictive policing:</p>
  
  <iframe 
    src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQuLdjZa_ULCrBhcdpMYHhUKs6BKKl8PX8KpVvc8gPlhbX3YdlLynuniqs-jo9GaXR3BReYBkjNPgpz/pubhtml?widget=true&amp;headers=false"
    width="100%" 
    height="600px" 
    frameborder="0"
    style="border: 2px solid #667eea; border-radius: 10px; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
  </iframe>
</div>
